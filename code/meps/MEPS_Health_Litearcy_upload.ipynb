{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0c32abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e155d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path = \"~/../../../../project/biocomplexity/sdad/projects_data/mc/data_commons/dc_education_training\" # specify the path to MEPS and ACS files here\n",
    "meps = pd.read_excel(path+\"h217.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9e2c8439",
   "metadata": {},
   "outputs": [],
   "source": [
    "meps.head\n",
    "# DUPERSID - PERSON ID (DUID + PID), PID - person's number\n",
    "cols_select = [\"DUPERSID\", \"PID\", \n",
    "              \"ADEXPL4\", \"ADEZUN4\", \"ADFHLP4\", \n",
    "              \"RACETHX\",\"RACEV1X\", \"RACEV2X\", \n",
    "              \"BORNUSA\", \"OTHLGSPK\", \"WHTLGSPK\" ,\"YRSINUS\", \n",
    "              \"EDUCYR\", \"HIDEG\", \n",
    "              \"SEX\",\n",
    "              \"AGEY2X\",\n",
    "              \"MARRYY2X\",\n",
    "              \"POVCATY1\", \"POVCATY2\", \"POVLEVY1\", \"POVLEVY2\"]\n",
    "questions = meps[cols_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "68c7c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode questions\n",
    "# drop -1 INAPPLICABLE and -15 CANNOT BE COMPUTED\n",
    "questions = questions.drop(questions[questions.ADEXPL4 < 0].index)\n",
    "questions = questions.drop(questions[questions.ADEZUN4 < 0].index)\n",
    "questions = questions.drop(questions[questions.ADFHLP4 < 0].index)\n",
    "# total score -- add scores together\n",
    "questions[\"tot_score\"] = questions.ADEXPL4 + questions.ADEZUN4 + questions.ADFHLP4\n",
    "#questions.tot_score.describe()\n",
    "# de-mean tot_score\n",
    "questions[\"std_score\"] = questions.tot_score - questions.tot_score.mean() \n",
    "#questions.std_score.describe()\n",
    "# helath literacy above average if the std_score is positive, and below average if negative\n",
    "questions[\"above_av\"] = 1\n",
    "questions.loc[questions['std_score'] <0 , 'above_av'] = 0 # above average means that a person USUALLY health literate\n",
    "#questions.above_av.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7626c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode chars as in ACS \n",
    "\n",
    "# age groups\n",
    "questions[\"age_less_18\"] = 0\n",
    "questions.loc[questions['AGEY2X'] < 18, 'age_less_18'] = 1\n",
    "questions[\"age_18_24\"] = 0\n",
    "questions.loc[(questions['AGEY2X'] <= 24) & (questions['AGEY2X'] >= 18), 'age_18_24'] = 1\n",
    "questions[\"age_25_39\"] = 0\n",
    "questions.loc[(questions['AGEY2X'] <= 39) & (questions['AGEY2X'] >= 25), 'age_25_39'] = 1\n",
    "questions[\"age_40_49\"] = 0\n",
    "questions.loc[(questions['AGEY2X'] <= 49) & (questions['AGEY2X'] >= 40), 'age_40_49'] = 1\n",
    "questions[\"age_50_64\"] = 0\n",
    "questions.loc[(questions['AGEY2X'] <= 64) & (questions['AGEY2X'] >= 50), 'age_50_64'] = 1\n",
    "questions[\"age_65_74\"] = 0\n",
    "questions.loc[(questions['AGEY2X'] <= 74) & (questions['AGEY2X'] >= 65), 'age_65_74'] = 1\n",
    "# reference category\n",
    "#questions[\"age_above_74\"] = 0\n",
    "#questions.loc[questions['AGEY2X'] > 74, 'age_above_74'] = 1\n",
    "\n",
    "# gender\n",
    "# reference category - male\n",
    "questions[\"female\"] = 0\n",
    "questions.loc[questions['SEX'] == 2, 'female'] = 1\n",
    "\n",
    "# race/ethnicity \n",
    "# reference category - white \n",
    "# questions[\"white\"] = 0\n",
    "# questions.loc[questions['RACETHX'] == 2, 'white'] = 1\n",
    "questions[\"black\"] = 0\n",
    "questions.loc[questions['RACETHX'] == 3, 'black'] = 1\n",
    "questions[\"hispanic\"] = 0\n",
    "questions.loc[questions['RACETHX'] == 1, 'hispanic'] = 1\n",
    "questions[\"asian_pi\"] = 0\n",
    "questions.loc[(questions['RACEV1X'] == 4) & (questions['RACETHX'] != 1), 'asian_pi'] = 1\n",
    "questions[\"native\"] = 0\n",
    "questions.loc[(questions['RACEV1X'] == 3) & (questions['RACETHX'] != 1), 'native'] = 1\n",
    "questions[\"mixed\"] = 0\n",
    "questions.loc[questions['RACETHX'] == 5, 'mixed'] = 1\n",
    "\n",
    "# education\n",
    "# reference category - no education data\n",
    "#questions['edu_mis'] = 0\n",
    "#questions.loc[(questions['HIDEG'] == -7) | (questions['HIDEG'] == -8) | (questions['HIDEG'] == -15), 'edu_mis'] = 1\n",
    "questions['HS_GED'] = 0\n",
    "questions.loc[(questions['HIDEG'] == 2) | (questions['HIDEG'] == 3), 'HS_GED'] = 1\n",
    "questions['no_edu'] = 0\n",
    "questions.loc[questions['HIDEG'] == 1, 'no_edu'] = 1\n",
    "questions['BS_degree'] = 0\n",
    "questions.loc[questions['HIDEG'] == 4, 'BS_degree'] = 1\n",
    "questions['above_BS'] = 0\n",
    "questions.loc[(questions['HIDEG'] == 5) | (questions['HIDEG'] == 6), 'above_BS'] = 1\n",
    "questions['oth_degree'] = 0\n",
    "questions.loc[questions['HIDEG'] == 7, 'oth_degree'] = 1\n",
    "\n",
    "# income \n",
    "# reference - above poverty line\n",
    "questions['below_PVL'] = 0\n",
    "questions.loc[questions['POVCATY2'] == 1, 'below_PVL'] = 1\n",
    "\n",
    "# marital status\n",
    "# reference - married\n",
    "#questions[\"married\"] = 0\n",
    "#questions.loc[questions['MARRYY2X'] == 1, 'married'] = 1\n",
    "questions[\"wid_sep_div\"] = 0\n",
    "questions.loc[(questions['MARRYY2X'] == 2) | (questions['MARRYY2X'] == 3)\n",
    "              | (questions['MARRYY2X'] == 4), 'wid_sep_div'] = 1\n",
    "questions[\"nev_married\"] = 0\n",
    "questions.loc[questions['MARRYY2X'] == 5, 'nev_married'] = 1\n",
    "\n",
    "# language spoken at home\n",
    "# reference - no info\n",
    "#questions['lang_mis'] = 0 \n",
    "#questions.loc[(questions['OTHLGSPK'] == -15) | (questions['OTHLGSPK'] == -8), 'lang_mis'] = 1\n",
    "questions['lang_eng'] = 0\n",
    "questions.loc[questions['OTHLGSPK'] == 2, 'lang_eng'] = 1\n",
    "questions['lang_oth'] = 0\n",
    "questions.loc[questions['OTHLGSPK'] == 1, 'lang_oth'] = 1\n",
    "\n",
    "# born in the US\n",
    "# reference - not born in the US\n",
    "questions['not_born_us'] = 0\n",
    "questions.loc[questions['BORNUSA'] == 1, 'not_born_us'] = 2\n",
    "questions['born_us'] = 0\n",
    "questions.loc[questions['BORNUSA'] == 1, 'born_us'] = 1\n",
    "#questions['born_mis'] = 0\n",
    "#questions.loc[(questions['BORNUSA'] == -15) | (questions['BORNUSA'] == -7) \n",
    "# | (questions['BORNUSA'] == -8) , 'born_mis'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8f1b516b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          DUPERSID  PID  ADEXPL4  ADEZUN4  ADFHLP4  RACETHX  RACEV1X  RACEV2X  \\\n",
       "8      2320008102  102        4        4        4        4        4        4   \n",
       "12     2320018102  102        4        4        1        2        1        1   \n",
       "13     2320018103  103        1        4        2        2        1        1   \n",
       "15     2320019102  102        3        2        2        2        1        1   \n",
       "18     2320022101  101        4        4        1        2        1        1   \n",
       "...           ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "14050  2329677102  102        4        4        2        2        1        1   \n",
       "14056  2329681102  102        3        4        2        2        1        1   \n",
       "14057  2329682101  101        4        4        1        2        1        1   \n",
       "14058  2329682102  102        3        3        2        2        1        1   \n",
       "14062  2329684102  102        3        4        2        2        1        1   \n",
       "\n",
       "       BORNUSA  OTHLGSPK  ...  above_BS  oth_degree  below_PVL  wid_sep_div  \\\n",
       "8            1         2  ...         1           0          0            0   \n",
       "12           1         2  ...         0           0          0            0   \n",
       "13           1         2  ...         0           0          0            0   \n",
       "15           1         2  ...         0           0          0            0   \n",
       "18           1         2  ...         0           0          0            0   \n",
       "...        ...       ...  ...       ...         ...        ...          ...   \n",
       "14050        1         2  ...         0           0          1            0   \n",
       "14056        1         2  ...         0           1          1            0   \n",
       "14057        1         2  ...         1           0          0            0   \n",
       "14058        1         2  ...         0           0          0            0   \n",
       "14062        1         2  ...         0           0          0            0   \n",
       "\n",
       "       nev_married  lang_eng  lang_oth  born_us  born_mis  not_born_us  \n",
       "8                0         1         0        1         0            2  \n",
       "12               0         1         0        1         0            2  \n",
       "13               1         1         0        1         0            2  \n",
       "15               0         1         0        1         0            2  \n",
       "18               0         1         0        1         0            2  \n",
       "...            ...       ...       ...      ...       ...          ...  \n",
       "14050            0         1         0        1         0            2  \n",
       "14056            0         1         0        1         0            2  \n",
       "14057            0         1         0        1         0            2  \n",
       "14058            0         1         0        1         0            2  \n",
       "14062            0         1         0        1         0            2  \n",
       "\n",
       "[3388 rows x 49 columns]>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head\n",
    "#questions.AGEY2X.unique()\n",
    "#questions.AGEY2X.describe()\n",
    "#questions.RACETHX.unique()\n",
    "#questions.SEX.unique()\n",
    "#questions.SEX.describe()\n",
    "#questions.HIDEG.unique()\n",
    "#questions.OTHLGSPK.unique()\n",
    "#questions.BORNUSA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "53e3f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = [\"std_score\"]\n",
    "#y_col = [\"above_av\"]\n",
    "X_cols = [\"age_less_18\", \"age_18_24\", \"age_25_39\", \"age_40_49\", \"age_50_64\", \"age_65_74\", \n",
    "             \"female\", \n",
    "             \"black\", \"hispanic\", \"asian_pi\", \"native\", \"mixed\", \n",
    "             \"HS_GED\", \"no_edu\", \"BS_degree\", \"above_BS\", \"oth_degree\",\n",
    "             \"below_PVL\", \n",
    "             \"wid_sep_div\", \"nev_married\", \n",
    "             \"lang_eng\", \"lang_oth\",\n",
    "             \"born_us\", \"not_born_us\"]\n",
    "y = questions[y_col]\n",
    "X = questions[X_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "55cd4c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14021</th>\n",
       "      <td>-1.994982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>3.005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10457</th>\n",
       "      <td>0.005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0.005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>0.005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-2.994982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>1.005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>-2.994982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11937</th>\n",
       "      <td>3.005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>-0.994982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>847 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       std_score\n",
       "14021  -1.994982\n",
       "13607   3.005018\n",
       "10457   0.005018\n",
       "5193    0.005018\n",
       "1777    0.005018\n",
       "...          ...\n",
       "898    -2.994982\n",
       "2211    1.005018\n",
       "13366  -2.994982\n",
       "11937   3.005018\n",
       "2822   -0.994982\n",
       "\n",
       "[847 rows x 1 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=42)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "83a6e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 square: -0.004109694920850782\n",
      "MAE:  1.240409215018545\n",
      "MSE:  2.707319545118017\n"
     ]
    }
   ],
   "source": [
    "# linear regression model\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(np.array(X_train), y_train)\n",
    "y_pred_lr = lin_reg.predict(X_test)\n",
    "mae=metrics.mean_absolute_error(y_test, y_pred_lr)\n",
    "mse=metrics.mean_squared_error(y_test, y_pred_lr)\n",
    "# Printing the metrics\n",
    "print('R2 square:',metrics.r2_score(y_test, y_pred_lr))\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "abf6cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:  -0.4281521253730547\n",
      "R2 square: -0.4281521253730547\n",
      "MAE:  1.4930016822635075\n",
      "MSE:  3.8506392100208555\n"
     ]
    }
   ],
   "source": [
    "# decision tree regressor\n",
    "tree_reg = tree.DecisionTreeRegressor()\n",
    "tree_reg.fit(np.array(X_train), y_train)\n",
    "y_pred_tr = tree_reg.predict(X_test)\n",
    "mae=metrics.mean_absolute_error(y_test, y_pred_tr)\n",
    "mse=metrics.mean_squared_error(y_test, y_pred_tr)\n",
    "# Printing the metrics\n",
    "print('Decision Tree: ', tree_reg.score(X_test,y_test))\n",
    "print('R2 square:',metrics.r2_score(y_test, y_pred_tr))\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d92e3b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  -0.14913123101146475\n",
      "R2 square: -0.14913123101146475\n",
      "MAE:  1.3443021145353728\n",
      "MSE:  3.098332241347491\n"
     ]
    }
   ],
   "source": [
    "# random forest:\n",
    "rf_reg = RandomForestRegressor(n_estimators=100)\n",
    "rf_reg.fit(np.array(X_train), y_train.values.ravel())\n",
    "y_pred_rf = rf_reg.predict(X_test)\n",
    "mae=metrics.mean_absolute_error(y_test, y_pred_rf)\n",
    "mse=metrics.mean_squared_error(y_test, y_pred_rf)\n",
    "# Printing the metrics\n",
    "print('Random Forest: ', rf_reg.score(X_test,y_test))\n",
    "print('R2 square:',metrics.r2_score(y_test, y_pred_rf))\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a41a09d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-efe365eb73ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred_lg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    181\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    182\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (only for binary outcome: above/below average)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(random_state=0)\n",
    "log_reg.fit(X_train, y_train.values.ravel())\n",
    "y_pred_lg = log_reg.predict(X_test)\n",
    "mae=metrics.mean_absolute_error(y_test, y_pred_lg)\n",
    "mse=metrics.mean_squared_error(y_test, y_pred_lg)\n",
    "# Printing the metrics\n",
    "print('Logistic Regression Score: ', log_reg.score(X_test,y_test))\n",
    "print('R2 square:',metrics.r2_score(y_test, y_pred_lg))\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ce6803be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Score:  -0.040067818302294445\n",
      "R2 square: -0.040067818302294445\n",
      "MAE:  1.2647076257435148\n",
      "MSE:  2.8042712334930813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_reg = GradientBoostingRegressor(random_state=0)\n",
    "gb_reg.fit(X_train, y_train.values.ravel())\n",
    "y_pred_gb = gb_reg.predict(X_test)\n",
    "mae=metrics.mean_absolute_error(y_test, y_pred_gb)\n",
    "mse=metrics.mean_squared_error(y_test, y_pred_gb)\n",
    "# Printing the metrics\n",
    "print('Gradient Boosting Regressor Score: ', gb_reg.score(X_test,y_test))\n",
    "print('R2 square:',metrics.r2_score(y_test, y_pred_gb))\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2e440c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.707319545118017\n",
      "3.8616047091681733\n",
      "3.098332241347491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, y_pred_lr))\n",
    "print(mean_squared_error(y_test, y_pred_tr))\n",
    "print(mean_squared_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e0312d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload ACS data\n",
    "acs_tr = pd.read_csv(path+\"HL_X_pred_tr.csv\", index_col=\"GEOID\")\n",
    "acs_ct = pd.read_csv(path+\"HL_X_pred_ct.csv\", index_col=\"GEOID\")\n",
    "acs_hd = pd.read_csv(path+\"HL_X_pred_hd.csv\", index_col=\"GEOID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3d3832ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict using the decision tree\n",
    "acs_tr = np.nan_to_num(acs_tr)\n",
    "acs_ct = np.nan_to_num(acs_ct)\n",
    "acs_hd = np.nan_to_num(acs_hd)\n",
    "\n",
    "y_acs_tr = tree_reg.predict(acs_tr)\n",
    "y_acs_ct = tree_reg.predict(acs_ct)\n",
    "y_acs_hd = tree_reg.predict(acs_hd)\n",
    "type(y_acs_hd.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6462af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_est_tr = pd.DataFrame(y_acs_tr.tolist())\n",
    "hl_est_tr[\"GEOID\"] = acs_tr.index\n",
    "\n",
    "hl_est_ct = pd.DataFrame(y_acs_ct.tolist())\n",
    "hl_est_ct[\"GEOID\"] = acs_ct.index\n",
    "\n",
    "hl_est_hd = pd.DataFrame(y_acs_hd.tolist())\n",
    "hl_est_hd[\"GEOID\"] = acs_hd.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "27d231f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_est_tr.to_csv('hl_est_tr.csv',\n",
    "                  index=False)\n",
    "hl_est_ct.to_csv('hl_est_ct.csv',\n",
    "                  index=False)\n",
    "hl_est_hd.to_csv('hl_est_hd.csv',\n",
    "                  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
